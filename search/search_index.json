{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to AutoRec Abstract Realistic recommender systems are often required to adapt to ever-changing data and tasks or to explore different models systematically. To address the need, we present AutoRec , an open-source automated machine learning (AutoML) platform extended from the TensorFlow ecosystem and, to our knowledge, the first framework to leverage AutoML for model search and hyperparameter tuning in deep recommendation models. AutoRec also supports a highly flexible pipeline that accommodates both sparse and dense inputs, rating prediction and click-through rate (CTR) prediction tasks, and an array of recommendation models. Lastly, AutoRec provides a simple, user-friendly API. Experiments conducted on the benchmark datasets reveal AutoRec is reliable and can identify models which resemble the best model without prior knowledge.","title":"Home"},{"location":"#welcome-to-autorec","text":"","title":"Welcome to AutoRec"},{"location":"#abstract","text":"Realistic recommender systems are often required to adapt to ever-changing data and tasks or to explore different models systematically. To address the need, we present AutoRec , an open-source automated machine learning (AutoML) platform extended from the TensorFlow ecosystem and, to our knowledge, the first framework to leverage AutoML for model search and hyperparameter tuning in deep recommendation models. AutoRec also supports a highly flexible pipeline that accommodates both sparse and dense inputs, rating prediction and click-through rate (CTR) prediction tasks, and an array of recommendation models. Lastly, AutoRec provides a simple, user-friendly API. Experiments conducted on the benchmark datasets reveal AutoRec is reliable and can identify models which resemble the best model without prior knowledge.","title":"Abstract"},{"location":"about/","text":"This package is developed by DATA LAB at Texas A&M University. Core Team Ting-Hsiang Wang : Qingquan Song : Xiaotian Han : Zirui Liu : Haifeng Jin : Xia \"Ben\" Hu : Project lead and maintainer.","title":"About"},{"location":"about/#core-team","text":"Ting-Hsiang Wang : Qingquan Song : Xiaotian Han : Zirui Liu : Haifeng Jin : Xia \"Ben\" Hu : Project lead and maintainer.","title":"Core Team"},{"location":"benchmark/","text":"","title":"Benchmark"},{"location":"install/","text":"Requirements Python 3 : Follow the TensorFlow install steps to install Python 3. Pip : Follow the TensorFlow install steps to install Pip. Tensorflow >= 2.2.0 : AutoRec is based on TensorFlow. Please follow this tutorial to install TensorFlow for python3. GPU Setup (Optional) : If you have GPUs on your machine and want to use them to accelerate the training, you can follow this tutorial to setup. Install AutoRec","title":"Installation"},{"location":"install/#requirements","text":"Python 3 : Follow the TensorFlow install steps to install Python 3. Pip : Follow the TensorFlow install steps to install Pip. Tensorflow >= 2.2.0 : AutoRec is based on TensorFlow. Please follow this tutorial to install TensorFlow for python3. GPU Setup (Optional) : If you have GPUs on your machine and want to use them to accelerate the training, you can follow this tutorial to setup.","title":"Requirements"},{"location":"install/#install-autorec","text":"","title":"Install AutoRec"},{"location":"preprocessor/","text":"[source] BaseProprocessor autorecsys . pipeline . preprocessor . BaseProprocessor ( dataset_path = None , train_path = None , val_path = None , test_size = None ) [source] BaseRatingPredictionProprocessor autorecsys . pipeline . preprocessor . BaseRatingPredictionProprocessor ( dataset_path = None , train_path = None , val_path = None , test_size = None ) for rating prediction recommendation methods [source] BaseCTRPreprocessor autorecsys . pipeline . preprocessor . BaseCTRPreprocessor ( dataset_path = None , train_path = None , val_path = None , test_size = None ) for click-through rate (CTR) recommendation methods [source] BasePointWiseProprocessor autorecsys . pipeline . preprocessor . BasePointWiseProprocessor ( dataset_path = None , train_path = None , val_path = None , test_size = None ) for PointWise recommendation methods, CTR for PointWise recommendation methods, rating prediction for Movielens and can also for the similar dataset [source] BasePairWiseProprocessor autorecsys . pipeline . preprocessor . BasePairWiseProprocessor ( dataset_path = None , train_path = None , val_path = None , test_size = None ) for PairWise recommendation methods [source] AvazuPreprocessor autorecsys . pipeline . preprocessor . AvazuPreprocessor ( dataset_path = \"./examples/datasets/avazu/sampled_train_10000.txt\" , ) for click-through rate (CTR) recommendation methods [source] load_data AvazuPreprocessor . load_data () Set the following variables: 1) self.used_column_names: set the variable here because column_names may be loaded from dataset header 2) self.pd_data: set the variable here because the dataframe contain loaded and transformed data 3) self.hash_sizes: set the variable here because it is inferred from pd_data Note: do not infer from fit_dictionary because there might not such file to load. On the other hand, transformed data is always available at the end of the file so infer from that 4) self.dtype_dict: set the variable because we use used_column_name as key, which can be loaded here :return: [source] split_data AvazuPreprocessor . split_data ( X , y , train_size , validate_size ) :param X: numpy array :param y: numpy array :param train_size: :param validate_size: :return: [source] preprocessing AvazuPreprocessor . preprocessing ( train_size , validate_size , random_state = 42 ) [source] CriteoPreprocessor autorecsys . pipeline . preprocessor . CriteoPreprocessor ( dataset_path = \"./examples/datasets/criteo_sample_10000/train_examples.txt\" , ) for click-through rate (CTR) recommendation methods [source] NetflixPrizePreprocessor autorecsys . pipeline . preprocessor . NetflixPrizePreprocessor ( dataset_path ) for rating prediction recommendation methods [source] MovielensPreprocessor autorecsys . pipeline . preprocessor . MovielensPreprocessor ( dataset_path , sep = \"::\" ) for rating prediction recommendation methods [source] MovielensCTRPreprocessor autorecsys . pipeline . preprocessor . MovielensCTRPreprocessor ( dataset_path , sep = \"::\" ) for PointWise recommendation methods, CTR for PointWise recommendation methods, rating prediction for Movielens and can also for the similar dataset","title":"Preprocessor"},{"location":"preprocessor/#baseproprocessor","text":"autorecsys . pipeline . preprocessor . BaseProprocessor ( dataset_path = None , train_path = None , val_path = None , test_size = None ) [source]","title":"BaseProprocessor"},{"location":"preprocessor/#baseratingpredictionproprocessor","text":"autorecsys . pipeline . preprocessor . BaseRatingPredictionProprocessor ( dataset_path = None , train_path = None , val_path = None , test_size = None ) for rating prediction recommendation methods [source]","title":"BaseRatingPredictionProprocessor"},{"location":"preprocessor/#basectrpreprocessor","text":"autorecsys . pipeline . preprocessor . BaseCTRPreprocessor ( dataset_path = None , train_path = None , val_path = None , test_size = None ) for click-through rate (CTR) recommendation methods [source]","title":"BaseCTRPreprocessor"},{"location":"preprocessor/#basepointwiseproprocessor","text":"autorecsys . pipeline . preprocessor . BasePointWiseProprocessor ( dataset_path = None , train_path = None , val_path = None , test_size = None ) for PointWise recommendation methods, CTR for PointWise recommendation methods, rating prediction for Movielens and can also for the similar dataset [source]","title":"BasePointWiseProprocessor"},{"location":"preprocessor/#basepairwiseproprocessor","text":"autorecsys . pipeline . preprocessor . BasePairWiseProprocessor ( dataset_path = None , train_path = None , val_path = None , test_size = None ) for PairWise recommendation methods [source]","title":"BasePairWiseProprocessor"},{"location":"preprocessor/#avazupreprocessor","text":"autorecsys . pipeline . preprocessor . AvazuPreprocessor ( dataset_path = \"./examples/datasets/avazu/sampled_train_10000.txt\" , ) for click-through rate (CTR) recommendation methods [source]","title":"AvazuPreprocessor"},{"location":"preprocessor/#load_data","text":"AvazuPreprocessor . load_data () Set the following variables: 1) self.used_column_names: set the variable here because column_names may be loaded from dataset header 2) self.pd_data: set the variable here because the dataframe contain loaded and transformed data 3) self.hash_sizes: set the variable here because it is inferred from pd_data Note: do not infer from fit_dictionary because there might not such file to load. On the other hand, transformed data is always available at the end of the file so infer from that 4) self.dtype_dict: set the variable because we use used_column_name as key, which can be loaded here :return: [source]","title":"load_data"},{"location":"preprocessor/#split_data","text":"AvazuPreprocessor . split_data ( X , y , train_size , validate_size ) :param X: numpy array :param y: numpy array :param train_size: :param validate_size: :return: [source]","title":"split_data"},{"location":"preprocessor/#preprocessing","text":"AvazuPreprocessor . preprocessing ( train_size , validate_size , random_state = 42 ) [source]","title":"preprocessing"},{"location":"preprocessor/#criteopreprocessor","text":"autorecsys . pipeline . preprocessor . CriteoPreprocessor ( dataset_path = \"./examples/datasets/criteo_sample_10000/train_examples.txt\" , ) for click-through rate (CTR) recommendation methods [source]","title":"CriteoPreprocessor"},{"location":"preprocessor/#netflixprizepreprocessor","text":"autorecsys . pipeline . preprocessor . NetflixPrizePreprocessor ( dataset_path ) for rating prediction recommendation methods [source]","title":"NetflixPrizePreprocessor"},{"location":"preprocessor/#movielenspreprocessor","text":"autorecsys . pipeline . preprocessor . MovielensPreprocessor ( dataset_path , sep = \"::\" ) for rating prediction recommendation methods [source]","title":"MovielensPreprocessor"},{"location":"preprocessor/#movielensctrpreprocessor","text":"autorecsys . pipeline . preprocessor . MovielensCTRPreprocessor ( dataset_path , sep = \"::\" ) for PointWise recommendation methods, CTR for PointWise recommendation methods, rating prediction for Movielens and can also for the similar dataset","title":"MovielensCTRPreprocessor"},{"location":"examples/ctr_autoint/","text":"import os os . environ [ \"CUDA_VISIBLE_DEVICES\" ] = \"7\" import logging import tensorflow as tf import numpy as np from autorecsys.auto_search import Search from autorecsys.pipeline import Input , DenseFeatureMapper , SparseFeatureMapper , SelfAttentionInteraction , MLPInteraction , PointWiseOptimizer from autorecsys.recommender import CTRRecommender # logging setting logging . basicConfig ( level = logging . INFO , format = ' %(asctime)s - %(name)s - %(levelname)s - %(message)s ' ) logging . basicConfig ( level = logging . DEBUG , format = ' %(asctime)s - %(name)s - %(levelname)s - %(message)s ' ) logger = logging . getLogger ( __name__ ) # load dataset mini_criteo = np . load ( \"./examples/datasets/criteo/criteo_2M.npz\" ) # TODO: preprocess train val split train_X = [ mini_criteo [ 'X_int' ] . astype ( np . float32 ), mini_criteo [ 'X_cat' ] . astype ( np . float32 )] train_y = mini_criteo [ 'y' ] val_X , val_y = train_X , train_y # build the pipeline. dense_input_node = Input ( shape = [ 13 ]) sparse_input_node = Input ( shape = [ 26 ]) dense_feat_emb = DenseFeatureMapper ( num_of_fields = 13 , embedding_dim = 2 )( dense_input_node ) # TODO: preprocess data to get sparse hash_size sparse_feat_emb = SparseFeatureMapper ( num_of_fields = 26 , hash_size = [ 1444 , 555 , 175781 , 128509 , 306 , 19 , 11931 , 630 , 4 , 93146 , 5161 , 174835 , 3176 , 28 , 11255 , 165206 , 11 , 4606 , 2017 , 4 , 172322 , 18 , 16 , 56456 , 86 , 43356 ], embedding_dim = 2 )( sparse_input_node ) attention_output = SelfAttentionInteraction ()([ dense_feat_emb , sparse_feat_emb ]) bottom_mlp_output = MLPInteraction ()([ dense_feat_emb ]) top_mlp_output = MLPInteraction ()([ attention_output , bottom_mlp_output ]) output = PointWiseOptimizer ()( top_mlp_output ) model = CTRRecommender ( inputs = [ dense_input_node , sparse_input_node ], outputs = output ) # AutoML search and predict. searcher = Search ( model = model , tuner = 'random' , tuner_params = { 'max_trials' : 2 , 'overwrite' : True }, ) searcher . search ( x = train_X , y = train_y , x_val = val_X , y_val = val_y , objective = 'val_BinaryCrossentropy' , batch_size = 10000 , epochs = 20 , callbacks = [ tf . keras . callbacks . EarlyStopping ( monitor = 'val_loss' , patience = 1 )] ) logger . info ( 'First 10 Predicted Ratings: {} ' . format ( searcher . predict ( x = val_X )[: 10 ])) logger . info ( 'Predicting Accuracy (logloss): {} ' . format ( searcher . evaluate ( x = val_X , y_true = val_y )))","title":"Ctr autoint"},{"location":"examples/ctr_autorec/","text":"import os os . environ [ \"CUDA_VISIBLE_DEVICES\" ] = \"7\" import logging import tensorflow as tf import numpy as np from autorecsys.auto_search import Search from autorecsys.pipeline import Input , DenseFeatureMapper , SparseFeatureMapper , HyperInteraction , PointWiseOptimizer from autorecsys.recommender import CTRRecommender # logging setting logging . basicConfig ( level = logging . INFO , format = ' %(asctime)s - %(name)s - %(levelname)s - %(message)s ' ) logging . basicConfig ( level = logging . DEBUG , format = ' %(asctime)s - %(name)s - %(levelname)s - %(message)s ' ) logger = logging . getLogger ( __name__ ) # load dataset mini_criteo = np . load ( \"./examples/datasets/criteo/criteo_2M.npz\" ) # TODO: preprocess train val split train_X = [ mini_criteo [ 'X_int' ] . astype ( np . float32 ), mini_criteo [ 'X_cat' ] . astype ( np . float32 )] train_y = mini_criteo [ 'y' ] val_X , val_y = train_X , train_y # build the pipeline. dense_input_node = Input ( shape = [ 13 ]) sparse_input_node = Input ( shape = [ 26 ]) dense_feat_emb = DenseFeatureMapper ( num_of_fields = 13 , embedding_dim = 16 )( dense_input_node ) # TODO: preprocess data to get sparse hash_size sparse_feat_emb = SparseFeatureMapper ( num_of_fields = 26 , hash_size = [ 1444 , 555 , 175781 , 128509 , 306 , 19 , 11931 , 630 , 4 , 93146 , 5161 , 174835 , 3176 , 28 , 11255 , 165206 , 11 , 4606 , 2017 , 4 , 172322 , 18 , 16 , 56456 , 86 , 43356 ], embedding_dim = 16 )( sparse_input_node ) sparse_feat_bottom_output = HyperInteraction ( meta_interator_num = 2 )([ sparse_feat_emb ]) dense_feat_bottom_output = HyperInteraction ( meta_interator_num = 2 )([ dense_feat_emb ]) top_mlp_output = HyperInteraction ( meta_interator_num = 2 )([ sparse_feat_bottom_output , dense_feat_bottom_output ]) output = PointWiseOptimizer ()( top_mlp_output ) model = CTRRecommender ( inputs = [ dense_input_node , sparse_input_node ], outputs = output ) # AutoML search and predict. searcher = Search ( model = model , tuner = 'random' , tuner_params = { 'max_trials' : 2 , 'overwrite' : True }, ) searcher . search ( x = train_X , y = train_y , x_val = val_X , y_val = val_y , objective = 'val_BinaryCrossentropy' , batch_size = 10000 , epochs = 20 , callbacks = [ tf . keras . callbacks . EarlyStopping ( monitor = 'val_loss' , patience = 1 )] ) logger . info ( 'First 10 Predicted Ratings: {} ' . format ( searcher . predict ( x = val_X )[: 10 ])) logger . info ( 'Predicting Accuracy (logloss): {} ' . format ( searcher . evaluate ( x = val_X , y_true = val_y )))","title":"Ctr autorec"},{"location":"examples/ctr_benchmark/","text":"import argparse import time import os os . environ [ \"CUDA_VISIBLE_DEVICES\" ] = \"1\" import logging import tensorflow as tf from autorecsys.auto_search import Search from autorecsys.pipeline import Input , LatentFactorMapper , DenseFeatureMapper , SparseFeatureMapper , \\ ElementwiseInteraction , FMInteraction , MLPInteraction , ConcatenateInteraction , \\ CrossNetInteraction , SelfAttentionInteraction , HyperInteraction , \\ PointWiseOptimizer from autorecsys.pipeline.preprocessor import MovielensPreprocessor from autorecsys.recommender import CTRRecommender # logging setting logging . basicConfig ( level = logging . INFO , format = ' %(asctime)s - %(name)s - %(levelname)s - %(message)s ' ) logging . basicConfig ( level = logging . DEBUG , format = ' %(asctime)s - %(name)s - %(levelname)s - %(message)s ' ) logger = logging . getLogger ( __name__ ) def build_dlrm ( emb_dict ): if 'user' in emb_dict or 'item' in emb_dict : emb_list = [ emb for _ , emb in emb_dict . items ()] output = MLPInteraction ( num_layers = 2 )( emb_list ) else : sparse_feat_mlp_output = [ MLPInteraction ()( [ emb_dict [ 'sparse' ]] )] if 'sparse' in emb_dict else [] dense_feat_mlp_output = [ MLPInteraction ()( [ emb_dict [ 'dense' ]] )] if 'dense' in emb_dict else [] output = MLPInteraction ( num_layers = 2 )( sparse_feat_mlp_output + dense_feat_mlp_output ) return output def build_deepfm ( emb_dict ): if 'user' in emb_dict or 'item' in emb_dict : emb_list = [ emb for _ , emb in emb_dict . items ()] fm_output = [ FMInteraction ()( emb_list )] bottom_mlp_output = [ MLPInteraction ( num_layers = 2 )( emb_list )] output = MLPInteraction ( num_layers = 2 )( fm_output + bottom_mlp_output ) else : fm_output = [ FMInteraction ()( [ emb_dict [ 'sparse' ]] )] if 'sparse' in emb_dict else [] bottom_mlp_output = [ MLPInteraction ()( [ emb_dict [ 'dense' ]] )] if 'dense' in emb_dict else [] output = MLPInteraction ( num_layers = 2 )( fm_output + bottom_mlp_output ) return output def build_crossnet ( emb_dict ): if 'user' in emb_dict or 'item' in emb_dict : emb_list = [ emb for _ , emb in emb_dict . items ()] fm_output = [ CrossNetInteraction ()( emb_list )] bottom_mlp_output = [ MLPInteraction ( num_layers = 2 )( emb_list )] output = MLPInteraction ( num_layers = 2 )( fm_output + bottom_mlp_output ) else : fm_output = [ CrossNetInteraction ()( [ emb_dict [ 'sparse' ]] )] if 'sparse' in emb_dict else [] bottom_mlp_output = [ MLPInteraction ()( [ emb_dict [ 'dense' ]] )] if 'dense' in emb_dict else [] output = MLPInteraction ( num_layers = 2 )( fm_output + bottom_mlp_output ) return output def build_autoint ( emb_dict ): if 'user' in emb_dict or 'item' in emb_dict : emb_list = [ emb for _ , emb in emb_dict . items ()] fm_output = [ SelfAttentionInteraction ()( emb_list )] bottom_mlp_output = [ MLPInteraction ( num_layers = 2 )( emb_list )] output = MLPInteraction ( num_layers = 2 )( fm_output + bottom_mlp_output ) else : fm_output = [ SelfAttentionInteraction ()( [ emb_dict [ 'sparse' ]] )] if 'sparse' in emb_dict else [] bottom_mlp_output = [ MLPInteraction ()( [ emb_dict [ 'dense' ]] )] if 'dense' in emb_dict else [] output = MLPInteraction ( num_layers = 2 )( fm_output + bottom_mlp_output ) return output def build_neumf ( emb_dict ): emb_list = [ emb for _ , emb in emb_dict . items ()] innerproduct_output = [ ElementwiseInteraction ( elementwise_type = \"innerporduct\" )( emb_list )] mlp_output = [ MLPInteraction ( num_layers = 2 )( emb_list )] output = innerproduct_output + mlp_output return output def build_autorec ( emb_dict ): if 'user' in emb_dict or 'item' in emb_dict : emb_list = [ emb for _ , emb in emb_dict . items ()] output = HyperInteraction ()( emb_list ) else : sparse_feat_bottom_output = [ HyperInteraction ( meta_interator_num = 2 )([ sparse_feat_emb ])] if 'sparse' in emb_dict else [] dense_feat_bottom_output = [ HyperInteraction ( meta_interator_num = 2 )([ dense_feat_emb ])] if 'dense' in emb_dict else [] top_mlp_output = HyperInteraction ( meta_interator_num = 2 )( sparse_feat_bottom_output + dense_feat_bottom_output ) output = HyperInteraction ( meta_interator_num = 2 )([ top_mlp_output ]) return output if __name__ == '__main__' : # parse args parser = argparse . ArgumentParser () parser . add_argument ( '-model' , type = str , help = 'input a model name' , default = 'dlrm' ) parser . add_argument ( '-data' , type = str , help = 'dataset name' , default = \"criteo\" ) parser . add_argument ( '-data_path' , type = str , help = 'dataset path' , default = './examples/datasets/ml-1m/ratings.dat' ) parser . add_argument ( '-sep' , type = str , help = 'dataset sep' ) parser . add_argument ( '-search' , type = str , help = 'input a search method name' , default = 'random' ) parser . add_argument ( '-batch_size' , type = int , help = 'batch size' , default = 10000 ) parser . add_argument ( '-trials' , type = int , help = 'try number' , default = 2 ) args = parser . parse_args () print ( \"args:\" , args ) if args . sep == None : args . sep = '::' # Load and preprocess dataset if args . data == \"ml\" : data = MovielensCTRPreprocessor ( args . data_path , sep = args . sep ) data . preprocessing ( test_size = 0.1 , random_state = 1314 ) train_X , train_y , val_X , val_y = data . train_X , data . train_y , data . val_X , data . val_y input = Input ( shape = [ 2 ]) user_emb = LatentFactorMapper ( feat_column_id = 0 , id_num = 10000 , embedding_dim = 64 )( input ) item_emb = LatentFactorMapper ( feat_column_id = 1 , id_num = 10000 , embedding_dim = 64 )( input ) emb_dict = { 'user' : user_emb , 'item' : item_emb } if args . data == \"criteo\" : # data = CriteoPreprocessor(args.data_path) import numpy as np mini_criteo = np . load ( \"./examples/datasets/criteo/criteo_1000.npz\" ) # TODO: preprocess train val split train_X = [ mini_criteo [ 'X_int' ] . astype ( np . float32 ), mini_criteo [ 'X_cat' ] . astype ( np . float32 )] train_y = mini_criteo [ 'y' ] val_X , val_y = train_X , train_y dense_input_node = Input ( shape = [ 13 ]) sparse_input_node = Input ( shape = [ 26 ]) input = [ dense_input_node , sparse_input_node ] dense_feat_emb = DenseFeatureMapper ( num_of_fields = 13 , embedding_dim = 16 )( dense_input_node ) sparse_feat_emb = SparseFeatureMapper ( num_of_fields = 26 , hash_size = [ 1444 , 555 , 175781 , 128509 , 306 , 19 , 11931 , 630 , 4 , 93146 , 5161 , 174835 , 3176 , 28 , 11255 , 165206 , 11 , 4606 , 2017 , 4 , 172322 , 18 , 16 , 56456 , 86 , 43356 ], embedding_dim = 16 )( sparse_input_node ) emb_dict = { 'dense' : dense_feat_emb , 'sparse' : sparse_feat_emb } # select model if args . model == 'dlrm' : output = build_dlrm ( emb_dict ) if args . model == 'deepfm' : output = build_deepfm ( emb_dict ) if args . model == 'crossnet' : output = build_neumf ( emb_dict ) if args . model == 'autoint' : output = build_autorec ( emb_dict ) if args . model == 'neumf' : output = build_autorec ( emb_dict ) if args . model == 'autorec' : output = build_autorec ( emb_dict ) output = PointWiseOptimizer ()( output ) model = CTRRecommender ( inputs = input , outputs = output ) # search and predict. searcher = Search ( model = model , tuner = args . search , ## hyperband, bayesian tuner_params = { 'max_trials' : args . trials , 'overwrite' : True } ) start_time = time . time () searcher . search ( x = train_X , y = train_y , x_val = val_X , y_val = val_y , objective = 'val_BinaryCrossentropy' , batch_size = args . batch_size , epochs = 20 , callbacks = [ tf . keras . callbacks . EarlyStopping ( monitor = 'val_loss' , patience = 1 )] ) end_time = time . time () print ( \"runing time:\" , end_time - start_time ) print ( \"args\" , args ) logger . info ( 'Predicted Ratings: {} ' . format ( searcher . predict ( x = val_X ))) logger . info ( 'Predicting Accuracy (mse): {} ' . format ( searcher . evaluate ( x = val_X , y_true = val_y )))","title":"Ctr benchmark"},{"location":"examples/ctr_crossnet/","text":"import os os . environ [ \"CUDA_VISIBLE_DEVICES\" ] = \"7\" import logging import tensorflow as tf import numpy as np from autorecsys.auto_search import Search from autorecsys.pipeline import Input , DenseFeatureMapper , SparseFeatureMapper , CrossNetInteraction , MLPInteraction , PointWiseOptimizer from autorecsys.recommender import CTRRecommender # logging setting logging . basicConfig ( level = logging . INFO , format = ' %(asctime)s - %(name)s - %(levelname)s - %(message)s ' ) logging . basicConfig ( level = logging . DEBUG , format = ' %(asctime)s - %(name)s - %(levelname)s - %(message)s ' ) logger = logging . getLogger ( __name__ ) # load dataset mini_criteo = np . load ( \"./examples/datasets/criteo/criteo_2M.npz\" ) # TODO: preprocess train val split train_X = [ mini_criteo [ 'X_int' ] . astype ( np . float32 ), mini_criteo [ 'X_cat' ] . astype ( np . float32 )] train_y = mini_criteo [ 'y' ] val_X , val_y = train_X , train_y # build the pipeline. dense_input_node = Input ( shape = [ 13 ]) sparse_input_node = Input ( shape = [ 26 ]) dense_feat_emb = DenseFeatureMapper ( num_of_fields = 13 , embedding_dim = 2 )( dense_input_node ) # TODO: preprocess data to get sparse hash_size sparse_feat_emb = SparseFeatureMapper ( num_of_fields = 26 , hash_size = [ 1444 , 555 , 175781 , 128509 , 306 , 19 , 11931 , 630 , 4 , 93146 , 5161 , 174835 , 3176 , 28 , 11255 , 165206 , 11 , 4606 , 2017 , 4 , 172322 , 18 , 16 , 56456 , 86 , 43356 ], embedding_dim = 2 )( sparse_input_node ) crossnet_output = CrossNetInteraction ()([ dense_feat_emb , sparse_feat_emb ]) bottom_mlp_output = MLPInteraction ()([ dense_feat_emb ]) top_mlp_output = MLPInteraction ()([ crossnet_output , bottom_mlp_output ]) output = PointWiseOptimizer ()( top_mlp_output ) model = CTRRecommender ( inputs = [ dense_input_node , sparse_input_node ], outputs = output ) # AutoML search and predict. searcher = Search ( model = model , tuner = 'random' , tuner_params = { 'max_trials' : 2 , 'overwrite' : True }, ) searcher . search ( x = train_X , y = train_y , x_val = val_X , y_val = val_y , objective = 'val_BinaryCrossentropy' , batch_size = 10000 , epochs = 20 , callbacks = [ tf . keras . callbacks . EarlyStopping ( monitor = 'val_loss' , patience = 1 )] ) logger . info ( 'First 10 Predicted Ratings: {} ' . format ( searcher . predict ( x = val_X )[: 10 ])) logger . info ( 'Predicting Accuracy (logloss): {} ' . format ( searcher . evaluate ( x = val_X , y_true = val_y )))","title":"Ctr crossnet"},{"location":"examples/ctr_deepfm/","text":"import os os . environ [ \"CUDA_VISIBLE_DEVICES\" ] = \"7\" import logging import tensorflow as tf import numpy as np from autorecsys.auto_search import Search from autorecsys.pipeline import Input , DenseFeatureMapper , SparseFeatureMapper , FMInteraction , MLPInteraction , PointWiseOptimizer from autorecsys.recommender import CTRRecommender # logging setting logging . basicConfig ( level = logging . INFO , format = ' %(asctime)s - %(name)s - %(levelname)s - %(message)s ' ) logging . basicConfig ( level = logging . DEBUG , format = ' %(asctime)s - %(name)s - %(levelname)s - %(message)s ' ) logger = logging . getLogger ( __name__ ) # load dataset mini_criteo = np . load ( \"./examples/datasets/criteo/criteo_2M.npz\" ) # TODO: preprocess train val split train_X = [ mini_criteo [ 'X_int' ] . astype ( np . float32 ), mini_criteo [ 'X_cat' ] . astype ( np . float32 )] train_y = mini_criteo [ 'y' ] val_X , val_y = train_X , train_y # build the pipeline. dense_input_node = Input ( shape = [ 13 ]) sparse_input_node = Input ( shape = [ 26 ]) dense_feat_emb = DenseFeatureMapper ( num_of_fields = 13 , embedding_dim = 2 )( dense_input_node ) # TODO: preprocess data to get sparse hash_size sparse_feat_emb = SparseFeatureMapper ( num_of_fields = 26 , hash_size = [ 1444 , 555 , 175781 , 128509 , 306 , 19 , 11931 , 630 , 4 , 93146 , 5161 , 174835 , 3176 , 28 , 11255 , 165206 , 11 , 4606 , 2017 , 4 , 172322 , 18 , 16 , 56456 , 86 , 43356 ], embedding_dim = 2 )( sparse_input_node ) fm_output = FMInteraction ()([ sparse_feat_emb ]) bottom_mlp_output = MLPInteraction ()([ dense_feat_emb ]) top_mlp_output = MLPInteraction ()([ fm_output , bottom_mlp_output ]) output = PointWiseOptimizer ()( top_mlp_output ) model = CTRRecommender ( inputs = [ dense_input_node , sparse_input_node ], outputs = output ) # AutoML search and predict. searcher = Search ( model = model , tuner = 'random' , tuner_params = { 'max_trials' : 2 , 'overwrite' : True }, ) searcher . search ( x = train_X , y = train_y , x_val = val_X , y_val = val_y , objective = 'val_BinaryCrossentropy' , batch_size = 10000 , epochs = 20 , callbacks = [ tf . keras . callbacks . EarlyStopping ( monitor = 'val_loss' , patience = 1 )] ) logger . info ( 'First 10 Predicted Ratings: {} ' . format ( searcher . predict ( x = val_X )[: 10 ])) logger . info ( 'Predicting Accuracy (logloss): {} ' . format ( searcher . evaluate ( x = val_X , y_true = val_y )))","title":"Ctr deepfm"},{"location":"examples/ctr_dlrm/","text":"import os os . environ [ \"CUDA_VISIBLE_DEVICES\" ] = \"7\" import logging import tensorflow as tf import numpy as np from autorecsys.auto_search import Search from autorecsys.pipeline import Input , DenseFeatureMapper , SparseFeatureMapper , MLPInteraction , PointWiseOptimizer from autorecsys.recommender import CTRRecommender # logging setting logging . basicConfig ( level = logging . INFO , format = ' %(asctime)s - %(name)s - %(levelname)s - %(message)s ' ) logging . basicConfig ( level = logging . DEBUG , format = ' %(asctime)s - %(name)s - %(levelname)s - %(message)s ' ) logger = logging . getLogger ( __name__ ) # load dataset mini_criteo = np . load ( \"./examples/datasets/criteo/criteo_2M.npz\" ) # TODO: preprocess train val split train_X = [ mini_criteo [ 'X_int' ] . astype ( np . float32 ), mini_criteo [ 'X_cat' ] . astype ( np . float32 )] train_y = mini_criteo [ 'y' ] val_X , val_y = train_X , train_y # build the pipeline. dense_input_node = Input ( shape = [ 13 ]) sparse_input_node = Input ( shape = [ 26 ]) dense_feat_emb = DenseFeatureMapper ( num_of_fields = 13 , embedding_dim = 16 )( dense_input_node ) # TODO: preprocess data to get sparse hash_size sparse_feat_emb = SparseFeatureMapper ( num_of_fields = 26 , hash_size = [ 1444 , 555 , 175781 , 128509 , 306 , 19 , 11931 , 630 , 4 , 93146 , 5161 , 174835 , 3176 , 28 , 11255 , 165206 , 11 , 4606 , 2017 , 4 , 172322 , 18 , 16 , 56456 , 86 , 43356 ], embedding_dim = 16 )( sparse_input_node ) sparse_feat_mlp_output = MLPInteraction ()([ sparse_feat_emb ]) dense_feat_mlp_output = MLPInteraction ()([ dense_feat_emb ]) top_mlp_output = MLPInteraction ( num_layers = 2 )([ sparse_feat_mlp_output , dense_feat_mlp_output ]) output = PointWiseOptimizer ()( top_mlp_output ) model = CTRRecommender ( inputs = [ dense_input_node , sparse_input_node ], outputs = output ) # AutoML search and predict. searcher = Search ( model = model , tuner = 'random' , tuner_params = { 'max_trials' : 2 , 'overwrite' : True }, ) searcher . search ( x = train_X , y = train_y , x_val = val_X , y_val = val_y , objective = 'val_BinaryCrossentropy' , batch_size = 10000 , epochs = 20 , callbacks = [ tf . keras . callbacks . EarlyStopping ( monitor = 'val_loss' , patience = 1 )] ) logger . info ( 'First 10 Predicted Ratings: {} ' . format ( searcher . predict ( x = val_X )[: 10 ])) logger . info ( 'Predicting Accuracy (logloss): {} ' . format ( searcher . evaluate ( x = val_X , y_true = val_y )))","title":"Ctr dlrm"},{"location":"examples/ctr_neumf/","text":"import os os . environ [ \"CUDA_VISIBLE_DEVICES\" ] = \"6\" import logging import tensorflow as tf from autorecsys.auto_search import Search from autorecsys.pipeline import Input , LatentFactorMapper , MLPInteraction , PointWiseOptimizer , ElementwiseInteraction from autorecsys.pipeline.preprocessor import MovielensCTRPreprocessor from autorecsys.recommender import CTRRecommender # logging setting logging . basicConfig ( level = logging . INFO , format = ' %(asctime)s - %(name)s - %(levelname)s - %(message)s ' ) logging . basicConfig ( level = logging . DEBUG , format = ' %(asctime)s - %(name)s - %(levelname)s - %(message)s ' ) logger = logging . getLogger ( __name__ ) # load dataset ml_1m = MovielensCTRPreprocessor ( \"./examples/datasets/ml-1m/ratings.dat\" ) ml_1m . preprocessing ( test_size = 0.1 , random_state = 1314 , num_neg = 10 , mult = 2 ) train_X , train_y , val_X , val_y = ml_1m . train_X , ml_1m . train_y , ml_1m . val_X , ml_1m . val_y # build the pipeline. input = Input ( shape = [ 2 ]) user_emb_gmf = LatentFactorMapper ( feat_column_id = 0 , id_num = 10000 , embedding_dim = 64 )( input ) item_emb_gmf = LatentFactorMapper ( feat_column_id = 1 , id_num = 10000 , embedding_dim = 64 )( input ) user_emb_mlp = LatentFactorMapper ( feat_column_id = 0 , id_num = 10000 , embedding_dim = 64 )( input ) item_emb_mlp = LatentFactorMapper ( feat_column_id = 1 , id_num = 10000 , embedding_dim = 64 )( input ) innerproduct_output = ElementwiseInteraction ( elementwise_type = \"innerporduct\" )([ user_emb_gmf , item_emb_gmf ]) mlp_output = MLPInteraction ()([ user_emb_mlp , item_emb_mlp ]) output = PointWiseOptimizer ()([ innerproduct_output , mlp_output ]) model = CTRRecommender ( inputs = input , outputs = output ) # AutoML search and predict. searcher = Search ( model = model , tuner = 'random' , tuner_params = { 'max_trials' : 10 , 'overwrite' : True }, ) searcher . search ( x = train_X , y = train_y , x_val = val_X , y_val = val_y , objective = 'val_BinaryCrossentropy' , batch_size = 256 , epochs = 20 , callbacks = [ tf . keras . callbacks . EarlyStopping ( monitor = 'val_loss' , patience = 1 )] ) logger . info ( 'Predicted Ratings: {} ' . format ( searcher . predict ( x = val_X ))) logger . info ( 'Predicting Accuracy (mse): {} ' . format ( searcher . evaluate ( x = val_X , y_true = val_y )))","title":"Ctr neumf"},{"location":"examples/rp_autorec/","text":"import os os . environ [ \"CUDA_VISIBLE_DEVICES\" ] = \"2\" import logging import tensorflow as tf from autorecsys.auto_search import Search from autorecsys.pipeline import Input , LatentFactorMapper , RatingPredictionOptimizer , HyperInteraction from autorecsys.pipeline.preprocessor import MovielensPreprocessor from autorecsys.recommender import RPRecommender # logging setting logging . basicConfig ( level = logging . INFO , format = ' %(asctime)s - %(name)s - %(levelname)s - %(message)s ' ) logging . basicConfig ( level = logging . DEBUG , format = ' %(asctime)s - %(name)s - %(levelname)s - %(message)s ' ) logger = logging . getLogger ( __name__ ) # load dataset ##Netflix Dataset # dataset_paths = [\"./examples/datasets/netflix-prize-data/combined_data_\" + str(i) + \".txt\" for i in range(1, 5)] # data = NetflixPrizePreprocessor(dataset_paths) #Movielens 1M Dataset data = MovielensPreprocessor ( \"./examples/datasets/ml-1m/ratings.dat\" ) ##Movielens 10M Dataset # data = MovielensPreprocessor(\"./examples/datasets/ml-10M100K/ratings.dat\") ##Movielens latest Dataset # data = MovielensPreprocessor(\"./examples/datasets/ml-latest/ratings.csv\", sep=',') data . preprocessing ( val_test_size = 0.1 , random_state = 1314 ) train_X , train_y = data . train_X , data . train_y val_X , val_y = data . val_X , data . val_y test_X , test_y = data . test_X , data . test_y user_num , item_num = data . user_num , data . item_num logger . info ( 'train_X size: {} ' . format ( train_X . shape )) logger . info ( 'train_y size: {} ' . format ( train_y . shape )) logger . info ( 'val_X size: {} ' . format ( val_X . shape )) logger . info ( 'val_y size: {} ' . format ( val_y . shape )) logger . info ( 'test_X size: {} ' . format ( test_X . shape )) logger . info ( 'test_y size: {} ' . format ( test_y . shape )) logger . info ( 'user total number: {} ' . format ( user_num )) logger . info ( 'item total number: {} ' . format ( item_num )) # build the pipeline. input = Input ( shape = [ 2 ]) user_emb = LatentFactorMapper ( feat_column_id = 0 , id_num = user_num , embedding_dim = 64 )( input ) item_emb = LatentFactorMapper ( feat_column_id = 1 , id_num = item_num , embedding_dim = 64 )( input ) output1 = HyperInteraction ()([ user_emb , item_emb ]) output2 = HyperInteraction ()([ output1 , user_emb , item_emb ]) output3 = HyperInteraction ()([ output1 , output2 , user_emb , item_emb ]) output4 = HyperInteraction ()([ output1 , output2 , output3 , user_emb , item_emb ]) output = RatingPredictionOptimizer ()( output4 ) model = RPRecommender ( inputs = input , outputs = output ) # AutoML search and predict. searcher = Search ( model = model , tuner = 'random' , ## hyperband, bayesian tuner_params = { 'max_trials' : 100 , 'overwrite' : True },) searcher . search ( x = train_X , y = train_y , x_val = val_X , y_val = val_y , objective = 'val_mse' , batch_size = 1024 , epochs = 10 , callbacks = [ tf . keras . callbacks . EarlyStopping ( monitor = 'val_loss' , patience = 1 )]) logger . info ( 'Predicting Val Dataset Accuracy (mse): {} ' . format ( searcher . evaluate ( x = val_X , y_true = val_y ))) logger . info ( 'Predicting Test Dataset Accuracy (mse): {} ' . format ( searcher . evaluate ( x = test_X , y_true = test_y )))","title":"Rp autorec"},{"location":"examples/rp_benchmark/","text":"import argparse import time import os import sys # os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\" import logging # logging setting logging . basicConfig ( stream = sys . stdout , level = logging . DEBUG , format = ' %(asctime)s - %(name)s - %(levelname)s - %(message)s ' ) # logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s') # logger = logging.getLogger(__name__) import tensorflow as tf from autorecsys.auto_search import Search from autorecsys.pipeline import Input , LatentFactorMapper , RatingPredictionOptimizer , HyperInteraction , MLPInteraction , \\ ElementwiseInteraction from autorecsys.pipeline.preprocessor import MovielensPreprocessor , NetflixPrizePreprocessor from autorecsys.recommender import RPRecommender def build_mf ( user_num , item_num ): input = Input ( shape = [ 2 ]) user_emb = LatentFactorMapper ( feat_column_id = 0 , id_num = user_num , embedding_dim = 64 )( input ) item_emb = LatentFactorMapper ( feat_column_id = 1 , id_num = item_num , embedding_dim = 64 )( input ) output = ElementwiseInteraction ( elementwise_type = \"innerporduct\" )([ user_emb , item_emb ]) output = RatingPredictionOptimizer ()( output ) model = RPRecommender ( inputs = input , outputs = output ) return model def build_gmf ( user_num , item_num ): input = Input ( shape = [ 2 ]) user_emb = LatentFactorMapper ( feat_column_id = 0 , id_num = user_num , embedding_dim = 64 )( input ) item_emb = LatentFactorMapper ( feat_column_id = 1 , id_num = item_num , embedding_dim = 64 )( input ) output = ElementwiseInteraction ( elementwise_type = \"innerporduct\" )([ user_emb , item_emb ]) output = RatingPredictionOptimizer ()( output ) model = RPRecommender ( inputs = input , outputs = output ) return model def build_mlp ( user_num , item_num ): input = Input ( shape = [ 2 ]) user_emb_mlp = LatentFactorMapper ( feat_column_id = 0 , id_num = user_num , embedding_dim = 64 )( input ) item_emb_mlp = LatentFactorMapper ( feat_column_id = 1 , id_num = user_num , embedding_dim = 64 )( input ) output = MLPInteraction ()([ user_emb_mlp , item_emb_mlp ]) output = RatingPredictionOptimizer ()( output ) model = RPRecommender ( inputs = input , outputs = output ) return model def build_neumf ( user_num , item_num ): input = Input ( shape = [ 2 ]) user_emb_gmf = LatentFactorMapper ( feat_column_id = 0 , id_num = user_num , embedding_dim = 64 )( input ) item_emb_gmf = LatentFactorMapper ( feat_column_id = 1 , id_num = item_num , embedding_dim = 64 )( input ) innerproduct_output = ElementwiseInteraction ( elementwise_type = \"innerporduct\" )([ user_emb_gmf , item_emb_gmf ]) user_emb_mlp = LatentFactorMapper ( feat_column_id = 0 , id_num = user_num , embedding_dim = 64 )( input ) item_emb_mlp = LatentFactorMapper ( feat_column_id = 1 , id_num = item_num , embedding_dim = 64 )( input ) mlp_output = MLPInteraction ()([ user_emb_mlp , item_emb_mlp ]) output = RatingPredictionOptimizer ()([ innerproduct_output , mlp_output ]) model = RPRecommender ( inputs = input , outputs = output ) return model def build_autorec ( user_num , item_num ): input = Input ( shape = [ 2 ]) user_emb_1 = LatentFactorMapper ( feat_column_id = 0 , id_num = user_num , embedding_dim = 64 )( input ) item_emb_1 = LatentFactorMapper ( feat_column_id = 1 , id_num = item_num , embedding_dim = 64 )( input ) user_emb_2 = LatentFactorMapper ( feat_column_id = 0 , id_num = user_num , embedding_dim = 64 )( input ) item_emb_2 = LatentFactorMapper ( feat_column_id = 1 , id_num = item_num , embedding_dim = 64 )( input ) output = HyperInteraction ()([ user_emb_1 , item_emb_1 , user_emb_2 , item_emb_2 ]) output = RatingPredictionOptimizer ()( output ) model = RPRecommender ( inputs = input , outputs = output ) return model if __name__ == '__main__' : # parse args parser = argparse . ArgumentParser () parser . add_argument ( '-model' , type = str , help = 'input a model name' ) parser . add_argument ( '-data' , type = str , help = 'dataset name' ) parser . add_argument ( '-data_path' , type = str , help = 'dataset path' ) parser . add_argument ( '-sep' , type = str , help = 'dataset sep' ) parser . add_argument ( '-search' , type = str , help = 'input a search method name' ) parser . add_argument ( '-batch_size' , type = int , help = 'batch size' ) parser . add_argument ( '-epochs' , type = int , help = 'epochs' ) parser . add_argument ( '-early_stop' , type = int , help = 'early stop' ) parser . add_argument ( '-trials' , type = int , help = 'try number' ) args = parser . parse_args () # print(\"args:\", args) if args . sep == None : args . sep = '::' # Load dataset if args . data == \"ml\" : data = MovielensPreprocessor ( args . data_path , sep = args . sep ) if args . data == \"netflix\" : dataset_paths = [ args . data_path + \"/combined_data_\" + str ( i ) + \".txt\" for i in range ( 1 , 5 )] data = NetflixPrizePreprocessor ( dataset_paths ) data . preprocessing ( val_test_size = 0.1 , random_state = 1314 ) train_X , train_y = data . train_X , data . train_y val_X , val_y = data . val_X , data . val_y test_X , test_y = data . test_X , data . test_y user_num , item_num = data . user_num , data . item_num logging . info ( 'train_X size: {} ' . format ( train_X . shape )) logging . info ( 'train_y size: {} ' . format ( train_y . shape )) logging . info ( 'val_X size: {} ' . format ( val_X . shape )) logging . info ( 'val_y size: {} ' . format ( val_y . shape )) logging . info ( 'test_X size: {} ' . format ( test_X . shape )) logging . info ( 'test_y size: {} ' . format ( test_y . shape )) logging . info ( 'user total number: {} ' . format ( user_num )) logging . info ( 'item total number: {} ' . format ( item_num )) # select model if args . model == 'mf' : model = build_mf ( user_num , item_num ) if args . model == 'mlp' : model = build_mlp ( user_num , item_num ) if args . model == 'gmf' : model = build_gmf ( user_num , item_num ) if args . model == 'neumf' : model = build_neumf ( user_num , item_num ) if args . model == 'autorec' : model = build_autorec ( user_num , item_num ) # search and predict. searcher = Search ( model = model , tuner = args . search , ## hyperband, bayesian tuner_params = { 'max_trials' : args . trials , 'overwrite' : True } ) start_time = time . time () searcher . search ( x = train_X , y = train_y , x_val = val_X , y_val = val_y , objective = 'val_mse' , batch_size = args . batch_size , epochs = args . epochs , callbacks = [ tf . keras . callbacks . EarlyStopping ( monitor = 'val_loss' , patience = args . early_stop )]) end_time = time . time () # print(\"Runing time:\", end_time - start_time) # print(\"Args\", args) logging . info ( 'Runing time: {} ' . format ( end_time - start_time )) logging . info ( 'Args: {} ' . format ( args )) logging . info ( 'Predicting Val Dataset Accuracy (mse): {} ' . format ( searcher . evaluate ( x = val_X , y_true = val_y ))) logging . info ( 'Predicting Test Dataset Accuracy (mse): {} ' . format ( searcher . evaluate ( x = test_X , y_true = test_y )))","title":"Rp benchmark"},{"location":"examples/rp_mf/","text":"import os os . environ [ \"CUDA_VISIBLE_DEVICES\" ] = \"5\" import tensorflow as tf # gpus = tf.config.experimental.list_physical_devices(device_type='GPU') # for gpu in gpus: # tf.config.experimental.set_memory_growth(gpu, True) # import tensorflow as tf # physical_devices = tf.config.list_physical_devices('GPU') # tf.config.experimental.set_memory_growth(physical_devices[0], True) import logging from autorecsys.auto_search import Search from autorecsys.pipeline import Input , LatentFactorMapper , RatingPredictionOptimizer , ElementwiseInteraction from autorecsys.pipeline.preprocessor import MovielensPreprocessor , NetflixPrizePreprocessor from autorecsys.recommender import RPRecommender # logging setting logging . basicConfig ( level = logging . INFO , format = ' %(asctime)s - %(name)s - %(levelname)s - %(message)s ' ) logging . basicConfig ( level = logging . DEBUG , format = ' %(asctime)s - %(name)s - %(levelname)s - %(message)s ' ) logger = logging . getLogger ( __name__ ) # load dataset ##Netflix Dataset # dataset_paths = [\"./examples/datasets/netflix-prize-data/combined_data_\" + str(i) + \".txt\" for i in range(1, 5)] # data = NetflixPrizePreprocessor(dataset_paths) #Movielens 1M Dataset data = MovielensPreprocessor ( \"./examples/datasets/ml-1m/ratings.dat\" ) ##Movielens 10M Dataset # data = MovielensPreprocessor(\"./examples/datasets/ml-10M100K/ratings.dat\") ##Movielens latest Dataset # data = MovielensPreprocessor(\"./examples/datasets/ml-latest/ratings.csv\", sep=',') data . preprocessing ( val_test_size = 0.1 , random_state = 1314 ) train_X , train_y = data . train_X , data . train_y val_X , val_y = data . val_X , data . val_y test_X , test_y = data . test_X , data . test_y user_num , item_num = data . user_num , data . item_num logger . info ( 'train_X size: {} ' . format ( train_X . shape )) logger . info ( 'train_y size: {} ' . format ( train_y . shape )) logger . info ( 'val_X size: {} ' . format ( val_X . shape )) logger . info ( 'val_y size: {} ' . format ( val_y . shape )) logger . info ( 'test_X size: {} ' . format ( test_X . shape )) logger . info ( 'test_y size: {} ' . format ( test_y . shape )) logger . info ( 'user total number: {} ' . format ( user_num )) logger . info ( 'item total number: {} ' . format ( item_num )) # build the pipeline. input = Input ( shape = [ 2 ]) user_emb = LatentFactorMapper ( feat_column_id = 0 , id_num = user_num , embedding_dim = 64 )( input ) item_emb = LatentFactorMapper ( feat_column_id = 1 , id_num = item_num , embedding_dim = 64 )( input ) output = ElementwiseInteraction ( elementwise_type = \"innerporduct\" )([ user_emb , item_emb ]) output = RatingPredictionOptimizer ()( output ) model = RPRecommender ( inputs = input , outputs = output ) # AutoML search and predict searcher = Search ( model = model , tuner = 'greedy' , # hyperband, greedy, bayesian tuner_params = { \"max_trials\" : 5 } ) searcher . search ( x = train_X , y = train_y , x_val = val_X , y_val = val_y , objective = 'val_mse' , batch_size = 1024 , epochs = 10 , callbacks = [ tf . keras . callbacks . EarlyStopping ( monitor = 'val_loss' , patience = 1 )]) logger . info ( 'Predicting Val Dataset Accuracy (mse): {} ' . format ( searcher . evaluate ( x = val_X , y_true = val_y ))) logger . info ( 'Predicting Test Dataset Accuracy (mse): {} ' . format ( searcher . evaluate ( x = test_X , y_true = test_y )))","title":"Rp mf"},{"location":"examples/rp_neumf/","text":"import os os . environ [ \"CUDA_VISIBLE_DEVICES\" ] = \"6\" import logging import tensorflow as tf from autorecsys.auto_search import Search from autorecsys.pipeline import Input , LatentFactorMapper , MLPInteraction , RatingPredictionOptimizer , \\ ElementwiseInteraction from autorecsys.pipeline.preprocessor import MovielensPreprocessor from autorecsys.recommender import RPRecommender # logging setting logging . basicConfig ( level = logging . INFO , format = ' %(asctime)s - %(name)s - %(levelname)s - %(message)s ' ) logging . basicConfig ( level = logging . DEBUG , format = ' %(asctime)s - %(name)s - %(levelname)s - %(message)s ' ) logger = logging . getLogger ( __name__ ) # load dataset ##Netflix Dataset # dataset_paths = [\"./examples/datasets/netflix-prize-data/combined_data_\" + str(i) + \".txt\" for i in range(1, 5)] # data = NetflixPrizePreprocessor(dataset_paths) #Movielens 1M Dataset data = MovielensPreprocessor ( \"./examples/datasets/ml-1m/ratings.dat\" ) ##Movielens 10M Dataset # data = MovielensPreprocessor(\"./examples/datasets/ml-10M100K/ratings.dat\") ##Movielens latest Dataset # data = MovielensPreprocessor(\"./examples/datasets/ml-latest/ratings.csv\", sep=',') data . preprocessing ( val_test_size = 0.1 , random_state = 1314 ) train_X , train_y = data . train_X , data . train_y val_X , val_y = data . val_X , data . val_y test_X , test_y = data . test_X , data . test_y user_num , item_num = data . user_num , data . item_num logger . info ( 'train_X size: {} ' . format ( train_X . shape )) logger . info ( 'train_y size: {} ' . format ( train_y . shape )) logger . info ( 'val_X size: {} ' . format ( val_X . shape )) logger . info ( 'val_y size: {} ' . format ( val_y . shape )) logger . info ( 'test_X size: {} ' . format ( test_X . shape )) logger . info ( 'test_y size: {} ' . format ( test_y . shape )) logger . info ( 'user total number: {} ' . format ( user_num )) logger . info ( 'item total number: {} ' . format ( item_num )) # build the pipeline. input = Input ( shape = [ 2 ]) user_emb_gmf = LatentFactorMapper ( feat_column_id = 0 , id_num = user_num , embedding_dim = 64 )( input ) item_emb_gmf = LatentFactorMapper ( feat_column_id = 1 , id_num = item_num , embedding_dim = 64 )( input ) innerproduct_output = ElementwiseInteraction ( elementwise_type = \"innerporduct\" )([ user_emb_gmf , item_emb_gmf ]) user_emb_mlp = LatentFactorMapper ( feat_column_id = 0 , id_num = user_num , embedding_dim = 64 )( input ) item_emb_mlp = LatentFactorMapper ( feat_column_id = 1 , id_num = item_num , embedding_dim = 64 )( input ) mlp_output = MLPInteraction ()([ user_emb_mlp , item_emb_mlp ]) output = RatingPredictionOptimizer ()([ innerproduct_output , mlp_output ]) model = RPRecommender ( inputs = input , outputs = output ) # AutoML search and predict searcher = Search ( model = model , tuner = 'greedy' , # random, greedy tuner_params = { \"max_trials\" : 5 , 'overwrite' : True } ) searcher . search ( x = train_X , y = train_y , x_val = val_X , y_val = val_y , objective = 'val_mse' , batch_size = 1024 , epochs = 10 , callbacks = [ tf . keras . callbacks . EarlyStopping ( monitor = 'val_loss' , patience = 1 )]) logger . info ( 'Predicting Val Dataset Accuracy (mse): {} ' . format ( searcher . evaluate ( x = val_X , y_true = val_y ))) logger . info ( 'Predicting Test Dataset Accuracy (mse): {} ' . format ( searcher . evaluate ( x = test_X , y_true = test_y )))","title":"Rp neumf"}]}